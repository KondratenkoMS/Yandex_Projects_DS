{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3810ba",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a302dd5d",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "Постройте модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d828796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d497aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8cee6f",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "951508b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae2a0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('C:/Users/Mikhail/оформление/Машинное обучение для текстов/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0651d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146790</th>\n",
       "      <td>Ahh shut the fuck up you douchebag sand nigger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>\"\\n\\nREPLY: There is no such thing as Texas Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115087</th>\n",
       "      <td>Reply\\nHey, you could at least mention Jasenov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48830</th>\n",
       "      <td>Thats fine, there is no deadline )   chi?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136034</th>\n",
       "      <td>\"\\n\\nDYK nomination of Mustarabim\\n Hello! You...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121992</th>\n",
       "      <td>\"\\n\\nSockpuppetry case\\n \\nYou have been accus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37282</th>\n",
       "      <td>Judging by what I've just read in an article, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64488</th>\n",
       "      <td>Todd and Copper\\nIn the first film they were l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16992</th>\n",
       "      <td>\"\\n\\n \\nYou have been blocked from editing for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138230</th>\n",
       "      <td>| decline=Can't find evidence of block either ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119101</th>\n",
       "      <td>Would you like to vote in that case. If yes, p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133505</th>\n",
       "      <td>Mmmm... yes... a pint of palestinian blood wou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149283</th>\n",
       "      <td>\"\\n\\nTalkback\\n '''''' talk \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40877</th>\n",
       "      <td>I guess I'll leave it for now If someone else ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25778</th>\n",
       "      <td>\"\\n\\n \"\"Lab\"\" created Alexandrite Chrysoberyl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76595</th>\n",
       "      <td>\"\\n\\nBTW, Judaispriest's final comment that go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41340</th>\n",
       "      <td>Officialsixsixsix\\n\\nHi. You may want to revis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141186</th>\n",
       "      <td>Budget \\n\\nIn the infobox is written that the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60326</th>\n",
       "      <td>\"\\nIndeed, please reference some sort of polic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140167</th>\n",
       "      <td>The 3-Me analog of fentanyl (3-MeF) was first ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "146790  Ahh shut the fuck up you douchebag sand nigger...      1\n",
       "2941    \"\\n\\nREPLY: There is no such thing as Texas Co...      0\n",
       "115087  Reply\\nHey, you could at least mention Jasenov...      0\n",
       "48830           Thats fine, there is no deadline )   chi?      0\n",
       "136034  \"\\n\\nDYK nomination of Mustarabim\\n Hello! You...      0\n",
       "121992  \"\\n\\nSockpuppetry case\\n \\nYou have been accus...      0\n",
       "37282   Judging by what I've just read in an article, ...      0\n",
       "64488   Todd and Copper\\nIn the first film they were l...      0\n",
       "16992   \"\\n\\n \\nYou have been blocked from editing for...      0\n",
       "138230  | decline=Can't find evidence of block either ...      0\n",
       "119101  Would you like to vote in that case. If yes, p...      0\n",
       "133505  Mmmm... yes... a pint of palestinian blood wou...      1\n",
       "149283                      \"\\n\\nTalkback\\n '''''' talk \"      0\n",
       "40877   I guess I'll leave it for now If someone else ...      0\n",
       "25778   \"\\n\\n \"\"Lab\"\" created Alexandrite Chrysoberyl ...      0\n",
       "76595   \"\\n\\nBTW, Judaispriest's final comment that go...      0\n",
       "41340   Officialsixsixsix\\n\\nHi. You may want to revis...      0\n",
       "141186  Budget \\n\\nIn the infobox is written that the ...      0\n",
       "60326   \"\\nIndeed, please reference some sort of polic...      0\n",
       "140167  The 3-Me analog of fentanyl (3-MeF) was first ...      0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20 ,random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43a16363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f615ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_sorted(data):\n",
    "    report = data.isna().sum().to_frame()\n",
    "    report = report.rename(columns = {0: 'missing_values'})\n",
    "    report['% of total'] = (report['missing_values'] / data.shape[0]).round(2)\n",
    "    print(report.sort_values(by = 'missing_values', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b6674c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       missing_values  % of total\n",
      "text                0         0.0\n",
      "toxic               0         0.0\n"
     ]
    }
   ],
   "source": [
    "miss_sorted(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc90b478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mikhail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#лишние символы и нижний регистр\n",
    "data['low_words'] = data['text'].apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x).lower())\n",
    "\n",
    "#стоп-слова\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "data['stop_words'] = data['low_words'].apply(lambda x: [w for w in x.split() if not w in stopwords])\n",
    "\n",
    "#леммы\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "data['lemmas'] = data['stop_words'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "data['lemmas'] = data['lemmas'].astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02edca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'match', 'background', 'colour', 'seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', 'really', 'trying', 'edit', 'wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['make', 'real', 'suggestion', 'improvement', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['second', 'time', 'asking', 'view', 'complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['ashamed', 'horrible', 'thing', 'put', 'talk'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['spitzer', 'umm', 'there', 'actual', 'article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['look', 'like', 'actually', 'put', 'speedy', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>['really', 'think', 'understand', 'came', 'ide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                   lemmas  \n",
       "0       ['explanation', 'edits', 'made', 'username', '...  \n",
       "1       ['aww', 'match', 'background', 'colour', 'seem...  \n",
       "2       ['hey', 'man', 'really', 'trying', 'edit', 'wa...  \n",
       "3       ['make', 'real', 'suggestion', 'improvement', ...  \n",
       "4           ['sir', 'hero', 'chance', 'remember', 'page']  \n",
       "...                                                   ...  \n",
       "159566  ['second', 'time', 'asking', 'view', 'complete...  \n",
       "159567  ['ashamed', 'horrible', 'thing', 'put', 'talk'...  \n",
       "159568  ['spitzer', 'umm', 'there', 'actual', 'article...  \n",
       "159569  ['look', 'like', 'actually', 'put', 'speedy', ...  \n",
       "159570  ['really', 'think', 'understand', 'came', 'ide...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['text', 'toxic', 'lemmas']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "915ec1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eeb25c",
   "metadata": {},
   "source": [
    "Токсичных сообщейний почти в 10 раз меньше, прежде чем проводить down\\upsample посмотрим как модель справляется без него и сравним его с dummyclassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961ba8a",
   "metadata": {},
   "source": [
    "### Разделим датасет на тестовую, валидационную и обучающую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "313410fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89758, 3), (39893, 3), (29920, 3))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_valid = train_test_split(data, test_size=0.25, random_state=12345)\n",
    "data_train, data_test = train_test_split(data_train, test_size=0.25, random_state=12345)\n",
    "data_train.shape, data_valid.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19f61f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64529\n",
       "1    36385\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f5d8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data_train['lemmas'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed8431e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mikhail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (89758, 113164)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663a871",
   "metadata": {},
   "source": [
    "Для предсказания ответов повторно вычислите величину TF-IDF для вектора с тестовой выборкой. Примените метод transform() к объекту TfidfVectorizer.\n",
    "Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e3f903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = data_train['lemmas']\n",
    "target_train = data_train['toxic']\n",
    "#__________________________\n",
    "features_valid = data_valid['lemmas']\n",
    "target_valid = data_valid['toxic']\n",
    "#__________________________\n",
    "features_test = data_test['lemmas']\n",
    "target_test = data_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "142b88a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89758,), (39893,), (29920,), (89758,), (39893,), (29920,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape,  features_valid.shape, features_test.shape, target_train.shape, target_valid.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8b8bce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_upsampled = data_train[:71806]['lemmas']\n",
    "target_train_upsampled = data_train[:71806]['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5834749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "047b3c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100914,), (100914,))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_upsampled, target_train_upsampled = upsample(features_train_upsampled, target_train_upsampled, 5 )\n",
    "features_train_upsampled.shape, target_train_upsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e908a",
   "metadata": {},
   "source": [
    "**сделаем не чистое разделение 50\\50 а 70\\30, т.к. в исходном датасете токсичных коментариев очень мало, то такое распределение не сделает сильный перевес в сторону токсичных комментариев**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "935729d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = count_tf_idf.transform(features_train)\n",
    "features_valid = count_tf_idf.transform(features_valid)\n",
    "features_test = count_tf_idf.transform(features_test)\n",
    "features_train_upsampled = count_tf_idf.transform(features_train_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97278fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89758, 113164), (39893, 113164), (29920, 113164), (100914, 113164))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, features_valid.shape, features_test.shape, features_train_upsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d8704",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e072ecf",
   "metadata": {},
   "source": [
    "### До upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648fcb04",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ce665f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.748597324126025"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_lr = LogisticRegression(max_iter=2000, class_weight='balanced', penalty='l2').fit(features_train, target_train)\n",
    "\n",
    "y_pred = model_lr.predict(features_valid)\n",
    "y_true = target_valid\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dff94a",
   "metadata": {},
   "source": [
    "### на test выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d0c4ad1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7452816386247255"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = model_lr.predict(features_test)\n",
    "y_true_test = target_test\n",
    "f1_score(y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad70913",
   "metadata": {},
   "source": [
    "### DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80112cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17021276595744683"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\").fit(features_train, target_train)\n",
    "\n",
    "y_pred = dummy_clf.predict(features_valid)\n",
    "y_true = target_valid\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad78ad3",
   "metadata": {},
   "source": [
    "### на test выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "986ffb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16708382001223648"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = dummy_clf.predict(features_test)\n",
    "y_true_test = target_test\n",
    "f1_score(y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9558fb",
   "metadata": {},
   "source": [
    "### После Upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b084f9c",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "95a2ba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7745734198509975"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_lr = LogisticRegression(max_iter=2000, penalty='l2').fit(features_train_upsampled, target_train_upsampled)\n",
    "\n",
    "y_pred = model_lr.predict(features_valid)\n",
    "y_true = target_valid\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a5d47",
   "metadata": {},
   "source": [
    "### на test выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79a7e1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685064935064937"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = model_lr.predict(features_test)\n",
    "y_true_test = target_test\n",
    "f1_score(y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058859e",
   "metadata": {},
   "source": [
    "### DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "90ad7913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1738336377220654"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\").fit(features_train, target_train)\n",
    "\n",
    "y_pred = dummy_clf.predict(features_valid)\n",
    "y_true = target_valid\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b06c0d",
   "metadata": {},
   "source": [
    "### на test выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ffd97876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16778411924419573"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = dummy_clf.predict(features_test)\n",
    "y_true_test = target_test\n",
    "f1_score(y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5bc15",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f16b223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fit_time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.745</td>\n",
       "      <td>5.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression_upsample</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DummyClassifier_upsample</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model_name  f1_score  fit_time_seconds\n",
       "0           LogisticRegression     0.745             5.180\n",
       "1  LogisticRegression_upsample     0.774             0.586\n",
       "2              DummyClassifier     0.167             0.017\n",
       "3     DummyClassifier_upsample     0.167             0.004"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Model_name': ['LogisticRegression', 'LogisticRegression_upsample', 'DummyClassifier', 'DummyClassifier_upsample'],\n",
    "     'f1_score': [0.745, 0.774, 0.167, 0.167],\n",
    "     'fit_time_seconds': [5.18, 0.586, 0.017, 0.004]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b45b53",
   "metadata": {},
   "source": [
    "1. Применение Upsampl'a повысил результаты до приемлимых 0.768 на тестовой выборке, таким образом баланс токсичных и не токсичных твитов имеет вес\n",
    "2. Dummyclassifire значительно уступает логистической регрессии\n",
    "3. Логичтическая регрессия отлично справилась с задачей и она проста и нетребовательна в использовании, другие модели даже не запустились"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c5f13",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2501,
    "start_time": "2021-06-14T00:14:26.295Z"
   },
   {
    "duration": 765,
    "start_time": "2021-06-14T00:14:30.504Z"
   },
   {
    "duration": 25,
    "start_time": "2021-06-14T00:14:32.562Z"
   },
   {
    "duration": 17,
    "start_time": "2021-06-14T00:14:42.366Z"
   },
   {
    "duration": 6,
    "start_time": "2021-06-14T00:14:49.644Z"
   },
   {
    "duration": 5,
    "start_time": "2021-06-14T00:14:50.512Z"
   },
   {
    "duration": 43,
    "start_time": "2021-06-14T00:14:50.786Z"
   },
   {
    "duration": 44924,
    "start_time": "2021-06-14T00:16:27.524Z"
   },
   {
    "duration": 9,
    "start_time": "2021-06-14T08:09:13.964Z"
   },
   {
    "duration": 113,
    "start_time": "2021-06-14T08:09:17.045Z"
   },
   {
    "duration": 4,
    "start_time": "2021-06-15T10:25:40.273Z"
   },
   {
    "duration": 2820,
    "start_time": "2021-06-15T10:25:40.280Z"
   },
   {
    "duration": 809,
    "start_time": "2021-06-15T10:25:43.103Z"
   },
   {
    "duration": 25,
    "start_time": "2021-06-15T10:25:43.915Z"
   },
   {
    "duration": 5,
    "start_time": "2021-06-15T10:25:43.943Z"
   },
   {
    "duration": 5,
    "start_time": "2021-06-15T10:25:43.950Z"
   },
   {
    "duration": 66,
    "start_time": "2021-06-15T10:25:43.957Z"
   },
   {
    "duration": 41984,
    "start_time": "2021-06-15T10:25:44.027Z"
   },
   {
    "duration": 329,
    "start_time": "2021-06-15T10:26:26.014Z"
   },
   {
    "duration": 12,
    "start_time": "2021-06-15T10:26:26.346Z"
   },
   {
    "duration": 127,
    "start_time": "2021-06-15T10:26:26.361Z"
   },
   {
    "duration": 11,
    "start_time": "2021-06-15T10:26:26.490Z"
   },
   {
    "duration": 11,
    "start_time": "2021-06-15T10:26:26.503Z"
   },
   {
    "duration": 45,
    "start_time": "2021-06-15T10:26:26.516Z"
   },
   {
    "duration": 8,
    "start_time": "2021-06-15T10:26:26.563Z"
   },
   {
    "duration": 2763,
    "start_time": "2021-06-15T10:26:26.601Z"
   },
   {
    "duration": 7651,
    "start_time": "2021-06-15T10:26:29.367Z"
   },
   {
    "duration": 5,
    "start_time": "2021-06-15T10:26:37.020Z"
   },
   {
    "duration": 10,
    "start_time": "2021-06-15T10:26:37.027Z"
   },
   {
    "duration": 12978,
    "start_time": "2021-06-15T10:26:37.039Z"
   },
   {
    "duration": 7,
    "start_time": "2021-06-15T10:26:50.021Z"
   },
   {
    "duration": 13840,
    "start_time": "2021-06-15T10:26:50.031Z"
   },
   {
    "duration": 32,
    "start_time": "2021-06-15T10:27:03.875Z"
   },
   {
    "duration": 27,
    "start_time": "2021-06-15T10:27:03.909Z"
   },
   {
    "duration": 18,
    "start_time": "2021-06-15T10:27:03.938Z"
   },
   {
    "duration": 9108,
    "start_time": "2021-06-15T10:27:03.958Z"
   },
   {
    "duration": 36,
    "start_time": "2021-06-15T10:27:13.068Z"
   },
   {
    "duration": 26,
    "start_time": "2021-06-15T10:27:13.106Z"
   },
   {
    "duration": 17,
    "start_time": "2021-06-15T10:27:13.135Z"
   },
   {
    "duration": 46,
    "start_time": "2021-06-15T10:27:13.155Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
